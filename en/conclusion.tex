\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

Although the official title of the research seeks to deal with inconsistencies, this work covers aspects from both error detection and correction (Chapter \ref{chap:conj_head} on \texttt{conj\_head}), and inconsistency detection and correction (Chapters \ref{chap:pos-harmony}, \ref{chap:lisca} and \ref{chap:failures}). 

In Chapter \ref{chap:pos-harmony}, we proposed a metric to attest the POS annotation consistency across treebanks that allegedly follow the same guidelines, for the same language. Through the use of the metric, we sought to answer how the different treebanks of a language, with variable size and genre distributions but following the same annotation guidelines, can be compared against each other. We also defined a reliable threshold on the proposed metric that would inform the annotators if the treebanks being compared are consistent in their annotation, or not. The metric was employed in the scope of UDv2.5 \citep{UDv2.5} data to compare the different treebanks of different languages, and highlighting the ones that are inconsistent in their annotation. To the best of our knowledge, this is the first such metric that compares the treebanks directly, without an added variable of tagger or parser performance.

In Chapter \ref{chap:conj_head}, we revisited the error type identified by \cite{alzetta2017dangerous} regarding the identification and correction of the head of a coordinating conjunction, referred to as \texttt{conj\_head}. We identified the different facets that would come in the way of solving the problem, and proposed solutions for them. The effectiveness of the proposed solutions was demonstrated on languages belonging to different language families, followed by an identification of the cases where the proposed solutions do not work as expected. While the experiments were done primarily on right-headed languages, the approach is extensible to left-headed languages as well, but not to languages with a mix of left and right-headedness\footnote{For details on right-headed and left-headed languages, refer to Section \ref{sec:direction}}.

Chapter \ref{chap:lisca} focused on the LISCA algorithm, proposed by \cite{lisca}. The algorithm needs a reference corpus to identify the inconsistencies in a treebank, based on the model framed off reference corpus. We checked the viability of the algorithm in a low-resource setting when there might not be a reference corpus to train the algorithm. We also investigated if the search space for the inconsistent arcs could be narrowed without a significant decrease in performance of the algorithm. Marking cross-validation technique as a viable option for the low-resource setting, we further examined the effect of the number of folds in $k$-fold cross-validation on the error mining process employing LISCA. A typology of different errors as identified in the experiment were also listed.

The experiment in Chapter \ref{chap:failures} sought to address the issue of drawing a line of distinction between \texttt{AUX} and \texttt{VERB} categories in an automatic manner. We employed an automatic classification technique to separate the individual tokens as belonging to either of \texttt{AUX} or \texttt{VERB}, or neither. While there was a small subset of instances that could be identified, the lower success rate of distinction between the two categories highlighted the challenging nature of the task and that the problem presents much room for improvement.

As the cost of storage falls lower, the size of the treebanks will increase. Essentially, at one point it might be impossible for human annotators to be part of the error-identification and error-correction process for the entire treebank. The current work is primarily aimed at finding the methods that don't need human annotators in the pipeline, and can be relied upon to fix the errors across different languages in a reliable manner. The research has been in some aspect successful at that front.

One major advantage of an iterative process, with respect to UD treebanks, is how individual error types can be focused on in each iteration. With the UD validator (cf. Level 5 checks in \verb|validate.py|\footnote{\url{https://github.com/UniversalDependencies/tools}} file) identifying and notifying the development teams of the individual errors, the process no longer suffers from a cold start problem. There is a high chance that with upcoming iterations, more and more of the experiments discussed in the document would be rendered obsolete for new treebanks, but they are still necessary to fix the issues in the present treebanks.

It is important to note here that the different problems listed in this thesis document rarely occur in isolation. More often than not, many of the problems are intertwined with each other, resulting in error propagation. Having said that, the corrections are also propagated in a similar fashion, whereby finding and correcting the right error solves multiple intertwined issues at the same time. Consider the example of experiment on \texttt{conj\_head} (in Chapter \ref{chap:conj_head}). Correction of this error instance in the specific case of \verb|eu| also corrected the case of falsely annotated non-projectivities in the trees.

Of the problems mentioned in the chapter titled `Future Work Recommendations' (Chapter \ref{chap:future}), there are some that were not worked on at all in the current research and are left for future researchers (For example, \texttt{nmod4obl} in Section  \ref{sec:probnmod4obl}). Additionally, some other problems are still being worked on, and thus do not fall into the scope of the current thesis document (For example, \texttt{FalseNonProjective} and \texttt{auxHead} in Sections \ref{future:nonproj} and \ref{future:auxHead} respectively).

The author hopes that future researchers will be able to tackle the problems listed in this thesis in a greater capacity, and improve upon the methods already discussed in this research wherever possible.