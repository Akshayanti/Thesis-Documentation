\chapter{Experiment 1: Intra-Language Inter-Treebank Harmony}
\label{chap:harmony}

\cite{alonso2016universal} note that if the two treebanks from the same language are as similar as possible, the differences in parsing accuracy (training parser on one of the treebanks, and using it to parse the other language) would be due to differences in dataset size, and domain change; but not due to differences in dependency convention.

\cite{klcpos3} show that KL-Divergence score of POS trigrams can be effectively used for source selection for POS Tagging in a delexicalised cross-language model transfer scenario. In their approach, they are able to select effectively not just a singular source, but also for source-weighting in multi-source transfer. Computing the KL-Divergence on POS trigrams, they call the measure as \(KL_{cpos^3}\), defined as follows:

\theoremstyle{definition}
\begin{definition}
\label{def:klcpos3}
\begin{equation}
\label{eqn:klcpos3}
    KL_{cpos^3}(tgt, src) = \sum_{\forall cpos^3 \in tgt}^{}f_{tgt}(cpos^3)\cdot\log\dfrac{f_{tgt}(cpos^3)}{f_{src}(cpos^3)}
\end{equation}
where \(cpos^3\) is a coarse POS tag trigram, and \\
\begin{equation}
\label{eqn:cpos}
    f(cpos^3) = f(cpos_{i-1}, cpos_{i}, cpos_{i+1}) = \frac{count(cpos_{i-1}, cpos_{i}, cpos_{i+1})}{\sum_{\forall cpos_{a,b,c}}{count(cpos_{a}, cpos_{b}, cpos_{c})}}
\end{equation}
with \(count_{src}(cpos^3) = 1\) for each unseen trigram.
\end{definition}

Intuitively, treebanks of the same language should be a better fit for single-source transfer than a treebank from another language, and so \(KL_{cpos^3}\) for a single-source transfer can be considered as a good benchmark for deciding this. However, \(KL_{cpos^3}\) is a variant of KL-Divergence, and thus is asymmetric. Therefore, we should rely on a metric that can calculate the divergence of the treebanks from each other, in both directions.

Combining the above two observations, we can arrive at a definition of treebank harmony.

\theoremstyle{definition}
\begin{definition}
\label{def:harmony}
Given two treebanks \(A\) and \(B\), we say the treebanks are in harmony with (or, are harmonious to) each other, iff
\begin{enumerate}
    \item The difference in labelled attachment scores (LAS) when trained on one treebank and tested on another, denoted by \(\theta_{LAS}\), is less than or equal to a given threshold \(\theta_1\). \\
    Mathematically, it can be represented as:
    \begin{equation}
    \label{eq:deprel_harmony}
        \theta_{LAS} = \vert {LAS}_{x,x} - {LAS}_{y,x} \vert \leq \theta_1 \hspace{5mm} \quad \forall [x, y \in \{A,B\}]
    \end{equation}
    where \(LAS_{P,Q}\) indicates LAS when trained on \(P\) and tested on \(Q\).
    \item The difference in \(KL_{cpos^3}\) scores of the treebanks calculated in both directions, denoted by \(\theta_{POS}\), is less than or equal to a given threshold \(\theta_2\). \\
    Mathematically, it can be represented as:
    \begin{equation}
    \label{eq:pos_harmony}
        \theta_{POS} = KL_{cpos^3}(A,B) + KL_{cpos^3}(B,A) \leq \theta_2
    \end{equation}
    where \(KL_{cpos^3}(P,Q)\) indicates \(KL_{cpos^3}\) score of \(Q\) as an estimator for \(P\).
\end{enumerate}

Mathematically, we denote two harmonious treebanks \(A,B\) as \(A \doteq B\) over (\(\theta_1, \theta_2\)). The relation of harmony is reflexive, symmetric, but not transitive.
\end{definition}

As mentioned earlier, there exist up to 6 different treebanks (not including PUD) for a given language. More often than not, the treebanks cover different domains, and are of different sizes. As such, it becomes an important criteria to determine the appropriate values for \(\theta_{1}\) and \(\theta_{2}\). If the values are too large, we run the risk of saying the treebanks are harmonious even when they might not be. Also, if the values are too small, we could be overlooking at the effect of domain change and dataset size, to mistake the two treebanks as being non-harmonious to each other.

\section{Dataset}
\label{sec:dataset_harmony}

Before we start tuning the hyper-parameters, we need to define our dataset. This experiment was conducted entirely on UDv2.5 data, without exceptions. To minimize the effect of dataset size disparity, we remove from consideration all the treebanks which are missing train data, as listed in Appendix \ref{app:treebank_data}. From these treebanks, we remove only the ones which do not contain any train data whatsoever.

Furthermore, there are treebanks which have data in the format where it needs to be fetched from another corpus and is not readily available for usage. We discard such treebanks as well from the consideration. Thus, the effective dataset for this entire experiment can be seen in Table \ref{tab:dataset_harmony} as follows:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|l|}
    \hline
    Language & Count & Treebank Names \\
    \hline \hline
    cs & 4 & CAC, CLTT, FicTree, PDT \\
    en & 4 & EWT, GUM, LinES, ParTUT \\
    es & 2 & AnCora, GSD \\
    et & 2 & EDT, EWT \\
    fi & 2 & FTB, TDT \\
    fr & 3 & GSD, ParTUT, Sequoia \\
    gl & 2 & CTG, TreeGal \\
    grc & 2 & Perseus, PROIEL \\
    it & 4 & ISDT, ParTUT, PoSTWITA, VIT \\
    ko & 2 & GSD, Kaist \\
    la & 3 & ITTB, Perseus, PROIEL \\
    lt & 2 & ALKSNIS, HSE \\
    nl & 2 & Alpino, LassySmall \\
    no & 3 & Bokmaal, Nynorsk, NynorskLIA \\
    pl & 2 & LFG, PDB \\
    pt & 2 & Bosque, GSD \\
    ro & 2 & Nonstandard, RRT \\
    ru & 3 & GSD, SynTagRus, Taiga \\
    sl & 2 & SSJ, SST \\
    sv & 2 & LinES, Talbanken \\
    \hline
    \end{tabular}
    \caption{Dataset for the Experiment on Harmony Between Treebanks, UDv2.4}
    \label{tab:dataset_harmony}
\end{table}