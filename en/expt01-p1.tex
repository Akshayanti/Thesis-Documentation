% \subsection{Other Factors}
% \label{ssec:others_theta2}

% We took into account the two major factors that causes a dip in parser performance. However, there are a few other factors that also affect the parser performance. We discuss some of those factors in this subsection, without performing any experiments on them. Thus, we don not account for these features in our definition of harmony of treebanks, as we argue that these features should be corrected in treebanks (wherever necessary, and possible), rather than being accounted for.

% We do not account anywhere for genre-specific vocabulary in any of the cases, since \cite{alonso2016universal} and \cite{RussianTreebanks} prove in their experiments that LAS scores are not affected by genre/topic-specific vocabulary.

% \subsubsection{Very Long Sentences}

% We define very long sentences as the sentences with more than the average number of tokens (defined on a per-language basis). As the sentence length increases, the distance of the nodes from the root of the sentence also increases. \cite{collins} showed how the distance between a token and the sentence root affects parser performance for trees. We can safely extrapolate on that information to extend it to the case of dependency parsing as well.

% As the number of very long sentences increase in the treebank, the parser performance on the individual sentences decreases, and therefore the total score on the entire treebank as well. While it might not always be possible to get rid of such very long sentences from the treebank, care should be taken to keep the count of such sentences as minimal as possible, or a separate parser could be trained on such sentences separately.

% \subsubsection{Non-Projective Structures}

% The presence of projective structures has been known to affect the parsing quality. The greater the difference in number of non-projective structures, the greater the difference in the parser performance. Minimising the number of non-projective structures in the treebanks is a definite way to reduce the degree by which the treebanks differ.

% \subsubsection{Differences in Annotation Strategies}

% In different treebanks from the same language, there might not be agreements in the annotation scheme. As \cite{RussianTreebanks} note, the difference in annotation of \textrussian{бы} (\textit{by}; would) in \verb|ru|-SynTagRus and \verb|ru|-Taiga as an auxillary in the different treebanks causes the parser trained on \verb|ru|-SynTagRus to be able to predict only 5\% of functional relations in \verb|ru|-Taiga. Other annotation inconsistencies, like those of tokenisation of multi-word entities (MWEs), parataxis, \verb|SYM| vs \verb|PUNCT|, etc. also cause a dip in parser performance. Such inconsistencies are often a result of individual team's decision on annotation strategies differing from each other.

% A correction on this aspect requires a more coherent dialogue between the different teams responsible for development of different treebanks, and should be encouraged. While it might not always be possible to catch these differences by an automatic tool also because we need to identify the areas where the annotation might be inconsistent between treebanks; the concept of variation nuclei \citep{boyd} can be used to some extent.

% \subsubsection{Other Incorrigible Factors}

% Apart from the above mentioned factors, the treebanks on the same language can also be influenced by the regional differences in the language. Consider the case of \verb|en|, and with reference to the difference in the spelling distinctions between American English and British English. In case of a lexicalized parsing scenario, the differences in spelling can make differences on how the parser reacts to different tokens. Another notable example is with respect to Spanish spoken in Spain, and the variation(s) of it with respect to Spanish as spoken in Latin America.

% \subsection{Brief Discussion on the metric}

% The architecture of a parser used for calculating \(\theta_{1}\) metric also would essentially change the variation of the scores, based on genres or on size. For example, the size-based disparity scores are in line with \cite{velldal-etal-2017-joint} where they report the similar patterns with respect to size variations. It might be an interesting study to extend the study based on this to different architectures and study the variation of scores in cases of genre-distribution as well as size-disparity.

\newpage
